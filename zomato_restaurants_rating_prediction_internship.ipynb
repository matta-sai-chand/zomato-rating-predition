{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zomato-restaurants-rating-prediction-internship.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrz7eZvw2eWc"
      },
      "source": [
        "**Reading the data into python**\n",
        "\n",
        "This is one of the most important steps in machine learning! You must understand the data and the domain well before trying to apply any machine learning algorithm.\n",
        "\n",
        "The data has one file \"zomato.csv\". This file contains 9551 restaurants details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuBJImdM2tJZ"
      },
      "source": [
        "Data description\n",
        "The business meaning of each column in the data is as below\n",
        "\n",
        "Restaurant ID: The id for each restaurant\n",
        "Restaurant Name: The brand/restaurant name\n",
        "Country Code: In which country the restaurant is operating\n",
        "City: In which city the restaurant is operating\n",
        "Address: What is the address of the restaurant\n",
        "Locality: What is the locality of the restaurant\n",
        "Locality Verbose: Detailed locality description\n",
        "Longitude: GPS longitude location\n",
        "Latitude: GPS latitude location\n",
        "Cuisines: Various type of food offered\n",
        "Currency: The business currency\n",
        "Has Table booking: Is advance table booking facility available?\n",
        "Has Online delivery: Does they take online food orders?\n",
        "Is delivering now: Is is open now?\n",
        "Switch to order menu: Whether switch to order menu is available?\n",
        "Price range: The price range of the restaurant\n",
        "Votes: The number of people who voted for the rating\n",
        "Average Cost for two: The typical cost for two people\n",
        "Rating: The final rating of the restaurant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX2tWP6Z2gSK"
      },
      "source": [
        "# Supressing the warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edGVrLZG2108"
      },
      "source": [
        "# Reading the dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "ZomatoData=pd.read_csv('/Users/farukh/Python Case Studies/zomato.csv', encoding='latin')\n",
        "print('Shape before deleting duplicate values:', ZomatoData.shape)\n",
        "\n",
        "# Removing duplicate rows if any\n",
        "ZomatoData=ZomatoData.drop_duplicates()\n",
        "print('Shape After deleting duplicate values:', ZomatoData.shape)\n",
        "\n",
        "# Printing sample data\n",
        "# Start observing the Quantitative/Categorical/Qualitative variables\n",
        "ZomatoData.head(10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CslTl0xK3B6o"
      },
      "source": [
        "Defining the problem statement:\n",
        "Create a Predictive model which can predict the future Rating of a restaurant\n",
        "Target Variable: Rating\n",
        "Predictors: location, menu, cost etc.\n",
        "Rating=1 Worst\n",
        "Rating=5 Best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CO62vOo3IOA"
      },
      "source": [
        "**Determining the type of Machine**\n",
        "Based on the problem statement you can understand that we need to create a supervised ML Regression model, as the target variable is Continuous."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xSxEEMS3P2N"
      },
      "source": [
        "**Looking at the distribution of Target variable\n",
        "If target variable's distribution is too skewed then the predictive modeling will not be possible.\n",
        "Bell curve is desirable but slightly positive skew or negative skew is also fine\n",
        "When performing Regression, make sure the histogram looks like a bell curve or slight skewed version of it. Otherwise it impacts the Machine Learning algorithms ability to learn all the scenarios.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbzLZEEz21y9"
      },
      "source": [
        "%matplotlib inline\n",
        "# Creating Bar chart as the Target variable is Continuous\n",
        "ZomatoData['Rating'].hist()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo5NnS0R3qU0"
      },
      "source": [
        "The data distribution of the target variable is satisfactory to proceed further. There are sufficient number of rows for each type of values to learn from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i0yrTpK3xJS"
      },
      "source": [
        "** There are four commands which are used for Basic data exploration in Python\n",
        "\n",
        "head() : This helps to see a few sample rows of the data\n",
        "info() : This provides the summarized information of the data\n",
        "describe() : This provides the descriptive statistical details of the data\n",
        "nunique(): This helps us to identify if a column is categorical or continuous **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC5_WNHm21w3"
      },
      "source": [
        "# Looking at sample rows in the data\n",
        "ZomatoData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFoDeNj21uB"
      },
      "source": [
        "# Observing the summarized information of data\n",
        "# Data types, Missing values based on number of non-null values Vs total rows etc.\n",
        "# Remove those variables from data which have too many missing values (Missing Values > 30%)\n",
        "# Remove Qualitative variables which cannot be used in Machine Learning\n",
        "ZomatoData.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SQm1bGA21qk"
      },
      "source": [
        "# Looking at the descriptive statistics of the data\n",
        "ZomatoData.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_S95B7K21ou"
      },
      "source": [
        "# Looking at the descriptive statistics of the data\n",
        "ZomatoData.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWONFcst21ln"
      },
      "source": [
        "# Feature Engineering\n",
        "# Function to count the number of cuisines\n",
        "def cuisine_counter(inpStr):\n",
        "    NumCuisines=len(str(inpStr).split(','))\n",
        "    return(NumCuisines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3eSkrBP21ju"
      },
      "source": [
        "# Creating a new feature in data\n",
        "# We will further explore the new feature just like other features\n",
        "ZomatoData['CuisineCount']=ZomatoData['Cuisines'].apply(cuisine_counter)\n",
        "ZomatoData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5c2gHR321hs"
      },
      "source": [
        "# Deleting those columns which are not useful in predictive analysis because these variables are qualitative\n",
        "UselessColumns = ['Restaurant ID', 'Restaurant Name','City','Address',\n",
        "                  'Locality', 'Locality Verbose','Cuisines']\n",
        "ZomatoData = ZomatoData.drop(UselessColumns,axis=1)\n",
        "ZomatoData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CNkrzNb21fm"
      },
      "source": [
        "#Visual Exploratory Data Analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gV0UZu521dh"
      },
      "source": [
        "# Plotting multiple bar charts at once for categorical variables\n",
        "# Since there is no default function which can plot bar charts for multiple columns at once\n",
        "# we are defining our own function for the same\n",
        "\n",
        "def PlotBarCharts(inpData, colsToPlot):\n",
        "    %matplotlib inline\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # Generating multiple subplots\n",
        "    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n",
        "    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n",
        "\n",
        "    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n",
        "        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UqBwUg021bR"
      },
      "source": [
        "#####################################################################\n",
        "# Calling the function\n",
        "PlotBarCharts(inpData=ZomatoData, colsToPlot=[\n",
        "    'Country Code', 'Currency', 'Has Table booking', 'Has Online delivery', 'Is delivering now',\n",
        "    'Switch to order menu','Price range'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEL5f3t121Zn"
      },
      "source": [
        "#Bar Charts Interpretation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV7I65wM21Xq"
      },
      "source": [
        "# Plotting histograms of multiple columns together\n",
        "ZomatoData.hist(['Longitude', 'Latitude', \n",
        "                 'Votes', 'Average Cost for two'], figsize=(18,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRB_iaqA21Vx"
      },
      "source": [
        "#Replacing outliers for 'Votes'\n",
        "# Finding nearest values to 4000 mark\n",
        "ZomatoData['Votes'][ZomatoData['Votes']<4000].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngvjrUxp21Pb"
      },
      "source": [
        "# Replacing outliers with nearest possibe value\n",
        "ZomatoData['Votes'][ZomatoData['Votes']>4000] =3986"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKVPKp1D21NH"
      },
      "source": [
        "# Finding nearest values to 50000 mark\n",
        "ZomatoData['Average Cost for two'][ZomatoData['Average Cost for two']<50000].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu2V8Cqz21J8"
      },
      "source": [
        "# Replacing outliers with nearest possibe value\n",
        "ZomatoData['Average Cost for two'][ZomatoData['Average Cost for two']>50000] =8000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T8ptdyU21E7"
      },
      "source": [
        "#Visualizing distribution after outlier treatment\n",
        "ZomatoData.hist(['Votes', 'Average Cost for two'], figsize=(18,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLLsWGqB5HXu"
      },
      "source": [
        "#Missing values treatment\n",
        "# Finding how many missing values are there for each column\n",
        "ZomatoData.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ax0uUNH5HV8"
      },
      "source": [
        "#Relationship exploration: Continuous Vs Continuous -- Scatter Charts\n",
        "ContinuousCols=['Longitude', 'Latitude', 'Votes', 'Average Cost for two']\n",
        "\n",
        "# Plotting scatter chart for each predictor vs the target variable\n",
        "for predictor in ContinuousCols:\n",
        "    ZomatoData.plot.scatter(x=predictor, y='Rating', figsize=(10,5), title=predictor+\" VS \"+ 'Rating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyNPjm-N5HTW"
      },
      "source": [
        "#Scatter charts interpretation\n",
        "# Calculating correlation matrix\n",
        "ContinuousCols=['Rating','Longitude', 'Latitude', 'Votes', 'Average Cost for two']\n",
        "\n",
        "# Creating the correlation matrix\n",
        "CorrelationData=ZomatoData[ContinuousCols].corr()\n",
        "CorrelationData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdzt-qxf5HRV"
      },
      "source": [
        "# Filtering only those columns where absolute correlation > 0.5 with Target Variable\n",
        "# reduce the 0.5 threshold if no variable is selected like in this case\n",
        "CorrelationData['Rating'][abs(CorrelationData['Rating']) > 0.2 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgRq2F4t5HMt"
      },
      "source": [
        "#Relationship exploration: Categorical Vs Continuous -- Box Plots\n",
        "# Box plots for Categorical Target Variable \"Rating\" and continuous predictors\n",
        "CategoricalColsList=['Has Table booking', 'Has Online delivery', 'Price range']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n",
        "\n",
        "# Creating box plots for each continuous predictor against the Target Variable \"Rating\"\n",
        "for PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n",
        "    ZomatoData.boxplot(column='Rating', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SWZDWEp5HKK"
      },
      "source": [
        "\n",
        "#Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC88b02L5HID"
      },
      "source": [
        "# Defining a function to find the statistical relationship with all the categorical variables\n",
        "def FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n",
        "    from scipy.stats import f_oneway\n",
        "\n",
        "    # Creating an empty list of final selected predictors\n",
        "    SelectedPredictors=[]\n",
        "    \n",
        "    print('##### ANOVA Results ##### \\n')\n",
        "    for predictor in CategoricalPredictorList:\n",
        "        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n",
        "        AnovaResults = f_oneway(*CategoryGroupLists)\n",
        "        \n",
        "        # If the ANOVA P-Value is <0.05, that means we reject H0\n",
        "        if (AnovaResults[1] < 0.05):\n",
        "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
        "            SelectedPredictors.append(predictor)\n",
        "        else:\n",
        "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
        "    \n",
        "    return(SelectedPredictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0LWqAr55HDo"
      },
      "source": [
        "# Calling the function to check which categorical variables are correlated with target\n",
        "# Calling the function to check which categorical variables are correlated with target\n",
        "CategoricalPredictorList=['Has Table booking', 'Has Online delivery', 'Price range']\n",
        "FunctionAnova(inpData=ZomatoData, \n",
        "              TargetVariable='Rating', \n",
        "              CategoricalPredictorList=CategoricalPredictorList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-9rMRoa5G_k"
      },
      "source": [
        "#Selecting final predictors for Machine Learning\n",
        "SelectedColumns=['Votes','Average Cost for two','Has Table booking',\n",
        "                 'Has Online delivery','Price range']\n",
        "\n",
        "# Selecting final columns\n",
        "DataForML=ZomatoData[SelectedColumns]\n",
        "DataForML.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgxScojW5G5T"
      },
      "source": [
        "# Saving this final data for reference during deployment\n",
        "DataForML.to_pickle('DataForML.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkhXM3fh6GNH"
      },
      "source": [
        "#Data Pre-processing for Machine Learning\n",
        "# Converting the binary nominal variable sex to numeric\n",
        "DataForML['Has Table booking'].replace({'Yes':1, 'No':0}, inplace=True)\n",
        "DataForML['Has Online delivery'].replace({'Yes':1, 'No':0}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcpD6wMr6GLY"
      },
      "source": [
        "# Treating all the nominal variables at once using dummy variables\n",
        "DataForML_Numeric=pd.get_dummies(DataForML)\n",
        "\n",
        "# Adding Target Variable to the data\n",
        "DataForML_Numeric['Rating']=ZomatoData['Rating']\n",
        "\n",
        "# Printing sample rows\n",
        "DataForML_Numeric.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsa-k2zB6GJx"
      },
      "source": [
        "#Machine Learning: Splitting the data into Training and Testing sample\n",
        "# Printing all the column names for our reference\n",
        "DataForML_Numeric.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fodDGI6GHv"
      },
      "source": [
        "# Separate Target Variable and Predictor Variables\n",
        "TargetVariable='Rating'\n",
        "Predictors=['Votes', 'Average Cost for two', 'Has Table booking',\n",
        "           'Has Online delivery', 'Price range']\n",
        "\n",
        "X=DataForML_Numeric[Predictors].values\n",
        "y=DataForML_Numeric[TargetVariable].values\n",
        "\n",
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jS5yLjb6GF2"
      },
      "source": [
        "#Standardization/Normalization of data\n",
        "### Sandardization of data ###\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# Choose either standardization or Normalization\n",
        "# On this data Min Max Normalization produced better results\n",
        "\n",
        "# Choose between standardization and MinMAx normalization\n",
        "#PredictorScaler=StandardScaler()\n",
        "PredictorScaler=MinMaxScaler()\n",
        "\n",
        "# Storing the fit object for later reference\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        "\n",
        "# Generating the standardized values of X\n",
        "X=PredictorScalerFit.transform(X)\n",
        "\n",
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lV3NLdh6GDw"
      },
      "source": [
        "# Sanity check for the sampled data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIuZ-hOo6GCE"
      },
      "source": [
        "#Multiple Linear Regression\n",
        "# Multiple Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "RegModel = LinearRegression()\n",
        "\n",
        "# Printing all the parameters of Linear regression\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "LREG=RegModel.fit(X_train,y_train)\n",
        "prediction=LREG.predict(X_test)\n",
        "\n",
        "# Taking the standardized values to original scale\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))/TestingDataResults['Rating'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__4YGfjI6F-M"
      },
      "source": [
        "#Decision Trees\n",
        "# Decision Trees (Multiple if-else statements!)\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "RegModel = DecisionTreeRegressor(max_depth=6,criterion='mse')\n",
        "# Good Range of Max_depth = 2 to 20\n",
        "\n",
        "# Printing all the parameters of Decision Tree\n",
        "print(RegModel)\n",
        "\n",
        "# Creating the model on Training Data\n",
        "DT=RegModel.fit(X_train,y_train)\n",
        "prediction=DT.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Measuring Goodness of fit in Training data\n",
        "print('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n",
        "\n",
        "# Plotting the feature importance for Top 10 most important columns\n",
        "%matplotlib inline\n",
        "feature_importances = pd.Series(DT.feature_importances_, index=Predictors)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "\n",
        "###########################################################################\n",
        "print('\\n##### Model Validation and Accuracy Calculations ##########')\n",
        "\n",
        "# Printing some sample values of prediction\n",
        "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
        "TestingDataResults[TargetVariable]=y_test\n",
        "TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n",
        "\n",
        "# Printing sample prediction values\n",
        "print(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n",
        "\n",
        "# Calculating the error for each row\n",
        "TestingDataResults['APE']=100 * ((abs(\n",
        "  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))/TestingDataResults['Rating'])\n",
        "\n",
        "MAPE=np.mean(TestingDataResults['APE'])\n",
        "MedianMAPE=np.median(TestingDataResults['APE'])\n",
        "\n",
        "Accuracy =100 - MAPE\n",
        "MedianAccuracy=100- MedianMAPE\n",
        "print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\n",
        "print('Median Accuracy on test data:', MedianAccuracy)\n",
        "\n",
        "\n",
        "# Defining a custom function to calculate accuracy\n",
        "# Make sure there are no zeros in the Target variable if you are using MAPE\n",
        "def Accuracy_Score(orig,pred):\n",
        "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
        "    #print('#'*70,'Accuracy:', 100-MAPE)\n",
        "    return(100-MAPE)\n",
        "\n",
        "# Custom Scoring MAPE calculation\n",
        "from sklearn.metrics import make_scorer\n",
        "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
        "\n",
        "# Importing cross validation function from sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Running 10-Fold Cross validation on a given algorithm\n",
        "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
        "Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\n",
        "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
        "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}